#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun Sep  2 15:33:56 2018

@author: nesma
# =============================================================================
# """

from __future__ import print_function
import keras
from keras.datasets import cifar10,mnist
from keras.models import Sequential,optimizers
from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten
import os
import psutil
import time
import datetime
import numpy as np

Dataset = cifar10 ##Change dataset name here options:(cifar10,mnist)
MNIST_batch_size = 128
MNIST_num_classes = 10
MNIST_epochs = 12
# input image dimensions
MNIST_img_rows, MNIST_img_cols = 28, 28


CIFAR_batch_size = 32
CIFAR_num_classes = 10
CIFAR_epochs = 12
CIFAR_save_dir = os.path.join(os.getcwd(), 'saved_models')
CIFAR_model_name = 'keras_cifar10_trained_model.h5'
        
def loadData():
    (x_train, y_train), (x_test, y_test) = Dataset.load_data()
    return x_train, y_train, x_test, y_test

def NormalizeData(x_train,x_test):
    x_train /= 255
    x_test /= 255
    return x_train, x_test
    
# convert class vectors to binary class matrices
# The result is a vector with a length equal to the number of categories.
def CategorizeData(y_train,y_test,num_classes):
    y_train = keras.utils.to_categorical(y_train, num_classes)
    y_test = keras.utils.to_categorical(y_test, num_classes)
    return y_train, y_test
        
def main():
    if Dataset is mnist:
        x_train, y_train, x_test, y_test = loadData()
        x_train = x_train.reshape(x_train.shape[0], MNIST_img_rows, MNIST_img_cols, 1)
        x_test = x_test.reshape(x_test.shape[0], MNIST_img_rows, MNIST_img_cols, 1)
        x_train = x_train.astype('float32')
        x_test = x_test.astype('float32')
        MNIST_input_shape = (MNIST_img_rows, MNIST_img_cols, 1)
         # normalizing the data to help with the training
        x_train, x_test = NormalizeData(x_train, x_test)
        y_train, y_test = CategorizeData(y_train,y_test,MNIST_num_classes)
                 
        # building model layers with the sequential model
        MNIST_model = Sequential()
        MNIST_model.add(Conv2D(32, kernel_size=(3, 3),
                         activation='relu',
                         input_shape=MNIST_input_shape))
        MNIST_model.add(Conv2D(64, (3, 3), activation='relu'))
        MNIST_model.add(MaxPooling2D(pool_size=(2, 2)))
        MNIST_model.add(Dropout(0.25))
        MNIST_model.add(Flatten())
        MNIST_model.add(Dense(128, activation='relu'))
        MNIST_model.add(Dropout(0.5))
        MNIST_model.add(Dense(MNIST_num_classes, activation='softmax'))
        
        MNIST_sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.5, nesterov=True)
        MNIST_model.compile(loss='categorical_crossentropy',
                      optimizer=MNIST_sgd,
                      metrics=['accuracy'])
        
        #Training the model
        MNIST_process = psutil.Process(os.getpid())
        print("before memory_percent",MNIST_process.memory_percent())
        print(psutil.cpu_percent(percpu=True))
        
        MNIST_start = time.time()
        print("start",MNIST_start)
        MNIST_model.fit(x_train, y_train,
                  batch_size=MNIST_batch_size,
                  epochs=MNIST_epochs,
                  verbose=1,
                  validation_data=(x_test, y_test))
        MNIST_end = time.time()
        
        MNIST_process = psutil.Process(os.getpid())
        print("after memory_percent",MNIST_process.memory_percent())
        print(psutil.cpu_percent(percpu=True))
        
        
        print("end", MNIST_end)
        
        print("Time Elapsed")
        print(str(datetime.timedelta(seconds= MNIST_end - MNIST_start)))
        print(MNIST_end - MNIST_start)
        
        
        #Model performance evaluation
        MNIST_Test_loss , MNIST_acc = MNIST_model.evaluate(x_test, y_test, verbose=1)
        print("Test Loss", MNIST_Test_loss)
        print("Test Accuracy", MNIST_acc)
        
        #MNIST_predicted_classes = MNIST_model.predict_classes(MNIST_x_test)
         
    elif Dataset is cifar10:
        x_train, y_train, x_test, y_test = loadData()
        x_train = x_train.astype('float32')
        x_test = x_test.astype('float32')
        x_train, x_test = NormalizeData(x_train, x_test)
        y_train, y_test = CategorizeData(y_train,y_test,CIFAR_num_classes)
        CIFAR_model = Sequential()
        CIFAR_model.add(Conv2D(32, (3, 3), padding='same',
                         input_shape=x_train.shape[1:]))
        CIFAR_model.add(Activation('relu'))
        CIFAR_model.add(Conv2D(32, (3, 3)))
        CIFAR_model.add(Activation('relu'))
        CIFAR_model.add(MaxPooling2D(pool_size=(2, 2)))
        CIFAR_model.add(Dropout(0.25))
        
        CIFAR_model.add(Conv2D(64, (3, 3), padding='same'))
        CIFAR_model.add(Activation('relu'))
        CIFAR_model.add(Conv2D(64, (3, 3)))
        CIFAR_model.add(Activation('relu'))
        CIFAR_model.add(MaxPooling2D(pool_size=(2, 2)))
        CIFAR_model.add(Dropout(0.25))
        
        CIFAR_model.add(Flatten())
        CIFAR_model.add(Dense(512))
        CIFAR_model.add(Activation('relu'))
        CIFAR_model.add(Dropout(0.5))
        CIFAR_model.add(Dense(CIFAR_num_classes))
        CIFAR_model.add(Activation('softmax')) 
        CIFAR_model.compile(loss='categorical_crossentropy',
                      optimizer='adam',
                      metrics=['accuracy'])
        
         
        CIFAR_current_process = psutil.Process()
        print("before memory_percent", CIFAR_current_process.memory_percent())
        print(psutil.cpu_percent(percpu=True))
        
        CIFAR_start = time.time()
        print("start",CIFAR_start)
               
        CIFAR_model.fit(x_train, y_train,
                      batch_size=CIFAR_batch_size,
                      epochs=CIFAR_epochs,
                      validation_data=(x_test, y_test),
                      shuffle=True)
        
        CIFAR_end = time.time()
        
        CIFAR_process = psutil.Process(os.getpid())
        print("after memory_percent",CIFAR_process.memory_percent())
        print(psutil.cpu_percent(percpu=True))
        print("end", CIFAR_end)
        
        
        print("Time Elapsed")
        print(str(datetime.timedelta(seconds= CIFAR_end - CIFAR_start)))
        print(CIFAR_end - CIFAR_start)
        
        # Save the model
        if not os.path.isdir(CIFAR_save_dir):
            os.makedirs(CIFAR_save_dir)
        CIFAR_model_path = os.path.join(CIFAR_save_dir, CIFAR_model_name)
        CIFAR_model.save(CIFAR_model_path)
        print('Saved trained model at %s ' % CIFAR_model_path)
        
        # Score trained model.
        CIFAR_scores = CIFAR_model.evaluate(x_test, y_test, verbose=1)
        print('Test loss:', CIFAR_scores[0])
        print('Test accuracy:', CIFAR_scores[1])
        
    else:
        print("No Dataset Choosed")
if __name__ == '__main__':
        main()
        
        
        
        
        
        
